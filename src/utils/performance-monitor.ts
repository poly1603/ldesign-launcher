/**
 * æ€§èƒ½ç›‘æ§å·¥å…·
 * 
 * æä¾›å®Œæ•´çš„æ€§èƒ½ç›‘æ§ã€åˆ†æå’ŒæŠ¥å‘ŠåŠŸèƒ½
 * 
 * @author LDesign Team
 * @since 2.1.0
 */

import { EventEmitter } from 'events'
import { performance, PerformanceObserver } from 'perf_hooks'
import { Logger } from './logger'
import v8 from 'v8'
import os from 'os'

export interface PerformanceMetrics {
  memory: {
    used: number
    total: number
    percentage: number
    rss: number
    external: number
    arrayBuffers: number
  }
  cpu: {
    usage: number
    loadAverage: number[]
    cores: number
  }
  timing: {
    startupTime: number
    buildTime: number
    hmrTime: number
    fileChangeResponseTime: number
  }
  heap: {
    totalHeapSize: number
    totalHeapSizeExecutable: number
    totalPhysicalSize: number
    usedHeapSize: number
    heapSizeLimit: number
    mallocedMemory: number
    peakMallocedMemory: number
  }
  requests?: {
    total: number
    successful: number
    failed: number
    averageResponseTime: number
  }
}

export interface PerformanceThresholds {
  memory?: {
    maxUsagePercent?: number
    maxHeapUsedMB?: number
  }
  cpu?: {
    maxUsagePercent?: number
  }
  timing?: {
    maxStartupMs?: number
    maxBuildMs?: number
    maxHmrMs?: number
  }
}

export interface PerformanceMonitorOptions {
  enabled?: boolean
  sampleInterval?: number
  thresholds?: PerformanceThresholds
  logger?: Logger
  autoReport?: boolean
  reportInterval?: number
  collectHeapSnapshot?: boolean
}

export class PerformanceMonitor extends EventEmitter {
  private enabled: boolean
  private sampleInterval: number
  private thresholds: PerformanceThresholds
  private logger: Logger
  private autoReport: boolean
  private reportInterval: number
  private collectHeapSnapshot: boolean
  
  private metrics: PerformanceMetrics
  private marks = new Map<string, number>()
  private measures = new Map<string, number[]>()
  private samplingTimer?: NodeJS.Timeout
  private reportTimer?: NodeJS.Timeout
  private observer?: PerformanceObserver
  private startTime: number
  private cpuUsageStart?: NodeJS.CpuUsage
  
  constructor(options: PerformanceMonitorOptions = {}) {
    super()
    
    this.enabled = options.enabled ?? true
    this.sampleInterval = options.sampleInterval || 5000 // 5ç§’é‡‡æ ·é—´éš”
    this.thresholds = options.thresholds || {}
    this.logger = options.logger || new Logger('PerformanceMonitor')
    this.autoReport = options.autoReport ?? false
    this.reportInterval = options.reportInterval || 60000 // 1åˆ†é’ŸæŠ¥å‘Šé—´éš”
    this.collectHeapSnapshot = options.collectHeapSnapshot ?? false
    
    this.startTime = Date.now()
    
    // åˆå§‹åŒ–metrics
    this.metrics = this.createEmptyMetrics()
    
    if (this.enabled) {
      this.start()
    }
  }
  
  /**
   * åˆ›å»ºç©ºçš„metricså¯¹è±¡
   */
  private createEmptyMetrics(): PerformanceMetrics {
    return {
      memory: {
        used: 0,
        total: 0,
        percentage: 0,
        rss: 0,
        external: 0,
        arrayBuffers: 0
      },
      cpu: {
        usage: 0,
        loadAverage: [0, 0, 0],
        cores: os.cpus().length
      },
      timing: {
        startupTime: 0,
        buildTime: 0,
        hmrTime: 0,
        fileChangeResponseTime: 0
      },
      heap: {
        totalHeapSize: 0,
        totalHeapSizeExecutable: 0,
        totalPhysicalSize: 0,
        usedHeapSize: 0,
        heapSizeLimit: 0,
        mallocedMemory: 0,
        peakMallocedMemory: 0
      }
    }
  }
  
  /**
   * å¯åŠ¨æ€§èƒ½ç›‘æ§
   */
  start(): void {
    if (!this.enabled) return
    
    this.logger.debug('æ€§èƒ½ç›‘æ§å·²å¯åŠ¨')
    
    // è®°å½•åˆå§‹CPUä½¿ç”¨
    this.cpuUsageStart = process.cpuUsage()
    
    // è®¾ç½®æ€§èƒ½è§‚å¯Ÿå™¨
    this.setupPerformanceObserver()
    
    // å¼€å§‹å®šæœŸé‡‡æ ·
    this.startSampling()
    
    // å¼€å§‹å®šæœŸæŠ¥å‘Š
    if (this.autoReport) {
      this.startAutoReporting()
    }
    
    this.emit('started')
  }
  
  /**
   * åœæ­¢æ€§èƒ½ç›‘æ§
   */
  stop(): void {
    this.logger.debug('æ€§èƒ½ç›‘æ§å·²åœæ­¢')
    
    if (this.samplingTimer) {
      clearInterval(this.samplingTimer)
      this.samplingTimer = undefined
    }
    
    if (this.reportTimer) {
      clearInterval(this.reportTimer)
      this.reportTimer = undefined
    }
    
    if (this.observer) {
      this.observer.disconnect()
      this.observer = undefined
    }
    
    this.emit('stopped')
  }
  
  /**
   * è®¾ç½®æ€§èƒ½è§‚å¯Ÿå™¨
   */
  private setupPerformanceObserver(): void {
    this.observer = new PerformanceObserver((items) => {
      items.getEntries().forEach((entry) => {
        this.logger.trace(`Performance entry: ${entry.name} (${entry.duration}ms)`)
        
        // è®°å½•åˆ°measures
        if (!this.measures.has(entry.name)) {
          this.measures.set(entry.name, [])
        }
        this.measures.get(entry.name)?.push(entry.duration)
      })
    })
    
    this.observer.observe({ entryTypes: ['measure', 'mark'] })
  }
  
  /**
   * å¼€å§‹é‡‡æ ·
   */
  private startSampling(): void {
    this.samplingTimer = setInterval(() => {
      this.collectMetrics()
    }, this.sampleInterval)
    
    // ç«‹å³é‡‡æ ·ä¸€æ¬¡
    this.collectMetrics()
  }
  
  /**
   * æ”¶é›†æ€§èƒ½æŒ‡æ ‡
   */
  private collectMetrics(): void {
    // æ”¶é›†å†…å­˜ä¿¡æ¯
    const memUsage = process.memoryUsage()
    const totalMem = os.totalmem()
    const freeMem = os.freemem()
    const usedMem = totalMem - freeMem
    
    this.metrics.memory = {
      used: Math.round(usedMem / 1024 / 1024),
      total: Math.round(totalMem / 1024 / 1024),
      percentage: Math.round((usedMem / totalMem) * 100),
      rss: Math.round(memUsage.rss / 1024 / 1024),
      external: Math.round(memUsage.external / 1024 / 1024),
      arrayBuffers: Math.round(memUsage.arrayBuffers / 1024 / 1024)
    }
    
    // æ”¶é›†CPUä¿¡æ¯
    if (this.cpuUsageStart) {
      const cpuUsage = process.cpuUsage(this.cpuUsageStart)
      const totalUsage = (cpuUsage.user + cpuUsage.system) / 1000 // å¾®ç§’è½¬æ¯«ç§’
      const elapsed = Date.now() - this.startTime
      this.metrics.cpu.usage = Math.min(100, Math.round((totalUsage / elapsed) * 100))
    }
    
    this.metrics.cpu.loadAverage = os.loadavg()
    
    // æ”¶é›†å †ä¿¡æ¯
    const heapStats = v8.getHeapStatistics()
    this.metrics.heap = {
      totalHeapSize: Math.round(heapStats.total_heap_size / 1024 / 1024),
      totalHeapSizeExecutable: Math.round(heapStats.total_heap_size_executable / 1024 / 1024),
      totalPhysicalSize: Math.round(heapStats.total_physical_size / 1024 / 1024),
      usedHeapSize: Math.round(heapStats.used_heap_size / 1024 / 1024),
      heapSizeLimit: Math.round(heapStats.heap_size_limit / 1024 / 1024),
      mallocedMemory: Math.round(heapStats.malloced_memory / 1024 / 1024),
      peakMallocedMemory: Math.round(heapStats.peak_malloced_memory / 1024 / 1024)
    }
    
    // æ£€æŸ¥é˜ˆå€¼
    this.checkThresholds()
    
    this.emit('metrics', this.metrics)
  }
  
  /**
   * æ£€æŸ¥æ€§èƒ½é˜ˆå€¼
   */
  private checkThresholds(): void {
    // æ£€æŸ¥å†…å­˜é˜ˆå€¼
    if (this.thresholds.memory) {
      if (this.thresholds.memory.maxUsagePercent && 
          this.metrics.memory.percentage > this.thresholds.memory.maxUsagePercent) {
        this.logger.warn(`å†…å­˜ä½¿ç”¨ç‡è¶…è¿‡é˜ˆå€¼: ${this.metrics.memory.percentage}%`)
        this.emit('threshold:memory', this.metrics.memory)
      }
      
      if (this.thresholds.memory.maxHeapUsedMB && 
          this.metrics.heap.usedHeapSize > this.thresholds.memory.maxHeapUsedMB) {
        this.logger.warn(`å †å†…å­˜ä½¿ç”¨è¶…è¿‡é˜ˆå€¼: ${this.metrics.heap.usedHeapSize}MB`)
        this.emit('threshold:heap', this.metrics.heap)
      }
    }
    
    // æ£€æŸ¥CPUé˜ˆå€¼
    if (this.thresholds.cpu?.maxUsagePercent && 
        this.metrics.cpu.usage > this.thresholds.cpu.maxUsagePercent) {
      this.logger.warn(`CPUä½¿ç”¨ç‡è¶…è¿‡é˜ˆå€¼: ${this.metrics.cpu.usage}%`)
      this.emit('threshold:cpu', this.metrics.cpu)
    }
  }
  
  /**
   * å¼€å§‹è‡ªåŠ¨æŠ¥å‘Š
   */
  private startAutoReporting(): void {
    this.reportTimer = setInterval(() => {
      this.generateReport()
    }, this.reportInterval)
  }
  
  /**
   * è®°å½•æ€§èƒ½æ ‡è®°
   */
  mark(name: string): void {
    this.marks.set(name, performance.now())
    performance.mark(name)
  }
  
  /**
   * æµ‹é‡æ€§èƒ½
   */
  measure(name: string, startMark: string, endMark?: string): number {
    const start = this.marks.get(startMark)
    if (!start) {
      this.logger.warn(`æ€§èƒ½æ ‡è®°ä¸å­˜åœ¨: ${startMark}`)
      return 0
    }
    
    const end = endMark ? this.marks.get(endMark) : performance.now()
    if (!end) {
      this.logger.warn(`æ€§èƒ½æ ‡è®°ä¸å­˜åœ¨: ${endMark}`)
      return 0
    }
    
    const duration = end - start
    
    // è®°å½•åˆ°measures
    if (!this.measures.has(name)) {
      this.measures.set(name, [])
    }
    this.measures.get(name)?.push(duration)
    
    // ä½¿ç”¨performance APIè®°å½•
    try {
      performance.measure(name, startMark, endMark)
    } catch (error) {
      // å¿½ç•¥é”™è¯¯ï¼ˆæ ‡è®°å¯èƒ½å·²è¢«æ¸…ç†ï¼‰
    }
    
    return duration
  }
  
  /**
   * è®°å½•è®¡æ—¶
   */
  recordTiming(type: 'startup' | 'build' | 'hmr' | 'fileChange', duration: number): void {
    switch (type) {
      case 'startup':
        this.metrics.timing.startupTime = duration
        break
      case 'build':
        this.metrics.timing.buildTime = duration
        break
      case 'hmr':
        this.metrics.timing.hmrTime = duration
        break
      case 'fileChange':
        this.metrics.timing.fileChangeResponseTime = duration
        break
    }
    
    this.logger.debug(`è®¡æ—¶è®°å½• [${type}]: ${duration}ms`)
  }
  
  /**
   * è·å–å½“å‰æŒ‡æ ‡
   */
  getMetrics(): PerformanceMetrics {
    return { ...this.metrics }
  }
  
  /**
   * è·å–ç»Ÿè®¡ä¿¡æ¯
   */
  getStats(): {
    averages: Record<string, number>
    totals: Record<string, number>
    counts: Record<string, number>
  } {
    const averages: Record<string, number> = {}
    const totals: Record<string, number> = {}
    const counts: Record<string, number> = {}
    
    this.measures.forEach((durations, name) => {
      if (durations.length > 0) {
        const total = durations.reduce((a, b) => a + b, 0)
        totals[name] = total
        counts[name] = durations.length
        averages[name] = total / durations.length
      }
    })
    
    return { averages, totals, counts }
  }
  
  /**
   * ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
   */
  generateReport(): string {
    const report: string[] = []
    
    report.push('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•')
    report.push('          æ€§èƒ½ç›‘æ§æŠ¥å‘Š')
    report.push('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•')
    report.push('')
    
    // å†…å­˜ä¿¡æ¯
    report.push('ğŸ“Š å†…å­˜ä½¿ç”¨:')
    report.push(`  â€¢ ç³»ç»Ÿå†…å­˜: ${this.metrics.memory.used}MB / ${this.metrics.memory.total}MB (${this.metrics.memory.percentage}%)`)
    report.push(`  â€¢ RSSå†…å­˜: ${this.metrics.memory.rss}MB`)
    report.push(`  â€¢ å †å†…å­˜: ${this.metrics.heap.usedHeapSize}MB / ${this.metrics.heap.heapSizeLimit}MB`)
    report.push('')
    
    // CPUä¿¡æ¯
    report.push('ğŸ’» CPUä½¿ç”¨:')
    report.push(`  â€¢ ä½¿ç”¨ç‡: ${this.metrics.cpu.usage}%`)
    report.push(`  â€¢ è´Ÿè½½å‡è¡¡: ${this.metrics.cpu.loadAverage.map(l => l.toFixed(2)).join(', ')}`)
    report.push(`  â€¢ æ ¸å¿ƒæ•°: ${this.metrics.cpu.cores}`)
    report.push('')
    
    // è®¡æ—¶ä¿¡æ¯
    if (this.metrics.timing.startupTime > 0 || this.metrics.timing.buildTime > 0) {
      report.push('â±ï¸ æ€§èƒ½è®¡æ—¶:')
      if (this.metrics.timing.startupTime > 0) {
        report.push(`  â€¢ å¯åŠ¨æ—¶é—´: ${this.metrics.timing.startupTime}ms`)
      }
      if (this.metrics.timing.buildTime > 0) {
        report.push(`  â€¢ æ„å»ºæ—¶é—´: ${this.metrics.timing.buildTime}ms`)
      }
      if (this.metrics.timing.hmrTime > 0) {
        report.push(`  â€¢ HMRæ—¶é—´: ${this.metrics.timing.hmrTime}ms`)
      }
      report.push('')
    }
    
    // ç»Ÿè®¡ä¿¡æ¯
    const stats = this.getStats()
    if (Object.keys(stats.averages).length > 0) {
      report.push('ğŸ“ˆ æ€§èƒ½ç»Ÿè®¡:')
      Object.entries(stats.averages).forEach(([name, avg]) => {
        report.push(`  â€¢ ${name}: å¹³å‡ ${avg.toFixed(2)}ms (å…± ${stats.counts[name]} æ¬¡)`)
      })
      report.push('')
    }
    
    report.push('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•')
    
    const reportStr = report.join('\n')
    
    if (this.autoReport) {
      console.log(reportStr)
    }
    
    this.emit('report', reportStr)
    
    return reportStr
  }
  
  /**
   * ç”Ÿæˆå †å¿«ç…§
   */
  async generateHeapSnapshot(): Promise<string | null> {
    if (!this.collectHeapSnapshot) {
      this.logger.warn('å †å¿«ç…§æ”¶é›†æœªå¯ç”¨')
      return null
    }
    
    try {
      const { writeHeapSnapshot } = await import('v8')
      const filename = `heap-${Date.now()}.heapsnapshot`
      const filepath = writeHeapSnapshot(filename)
      this.logger.info(`å †å¿«ç…§å·²ä¿å­˜: ${filepath}`)
      return filepath
    } catch (error) {
      this.logger.error('ç”Ÿæˆå †å¿«ç…§å¤±è´¥', error)
      return null
    }
  }
  
  /**
   * é‡ç½®æ‰€æœ‰æŒ‡æ ‡
   */
  reset(): void {
    this.metrics = this.createEmptyMetrics()
    this.marks.clear()
    this.measures.clear()
    this.startTime = Date.now()
    this.cpuUsageStart = process.cpuUsage()
    
    this.logger.debug('æ€§èƒ½æŒ‡æ ‡å·²é‡ç½®')
    this.emit('reset')
  }
  
  /**
   * é”€æ¯ç›‘æ§å™¨
   */
  destroy(): void {
    this.stop()
    this.removeAllListeners()
    this.reset()
  }
}

/**
 * åˆ›å»ºæ€§èƒ½ç›‘æ§å™¨å®ä¾‹
 */
export function createPerformanceMonitor(options?: PerformanceMonitorOptions): PerformanceMonitor {
  return new PerformanceMonitor(options)
}

// å¯¼å‡ºé»˜è®¤å®ä¾‹
export const performanceMonitor = new PerformanceMonitor({
  enabled: process.env.NODE_ENV === 'development' || process.env.PERF_MONITOR === 'true',
  autoReport: process.env.PERF_REPORT === 'true'
})